{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset of Digital hand writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Plot adhoc mnist instances\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# Print Predicted digits vector\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train - training input size (60000, 28, 28)\n",
      "y_train - training result size (60000,)\n",
      "\n",
      "X_test - Validation input size (10000, 28, 28)\n",
      "y_test - Validation result size (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train - training input size {}\".format(X_train.shape))\n",
    "print (\"y_train - training result size {}\\n\".format(y_train.shape))\n",
    "\n",
    "print (\"X_test - Validation input size {}\".format(X_test.shape))\n",
    "print (\"y_test - Validation result size {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# E.g. Plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple Artificial Neural Network for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_trainOrig = X_train\n",
    "X_testOrig = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data - Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix size X_train = (60000, 784), test matrix size X_test = (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Flatten 28x28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2] # 28 * 28 = 784 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "print (\"Training matrix size X_train = {}, test matrix size X_test = {}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data - Normalize Pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pixel value before Normalization = 255.0\n",
      "Max pixel value post Normalization= 1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalize inputs from 0-255 to 0-1\n",
    "print (\"Max pixel value before Normalization = {}\".format(X_train.max())) # 255 is the max\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "print (\"Max pixel value post Normalization= {}\".format(X_train.max())) # 1 is the max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data - Convert Ground truth to One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes - 10\n"
     ]
    }
   ],
   "source": [
    "# One hot encode outputs (i.e. convert number into array, i.e. 5 - [0 0 0 0 1 0 0 0 0 0] to handle one vs all)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # Now shape is 10000 x 10 as each number is converted as array\n",
    "\n",
    "print (\"Number of classes - {}\".format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation Class\n",
    "simple neural network with one hidden layer with the same number of neurons as there are inputs (784). A rectifier activation function is used for the neurons in the hidden layer. \n",
    "A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the model’s output prediction. \n",
    "Logarithmic loss is used as the loss function (called categorical_crossentropy in Keras) and the efficient ADAM gradient descent algorithm is used to learn the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model\n",
    "def baseline_model(num_pixels, num_classes):\n",
    "    # Create Model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation ='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation = 'softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model(num_pixels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.2783 - acc: 0.9210 - val_loss: 0.1414 - val_acc: 0.9576\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.1116 - acc: 0.9676 - val_loss: 0.0924 - val_acc: 0.9706\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0718 - acc: 0.9796 - val_loss: 0.0783 - val_acc: 0.9771\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0504 - acc: 0.9857 - val_loss: 0.0741 - val_acc: 0.9769\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0374 - acc: 0.9892 - val_loss: 0.0668 - val_acc: 0.9795\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0270 - acc: 0.9926 - val_loss: 0.0624 - val_acc: 0.9804\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0208 - acc: 0.9947 - val_loss: 0.0619 - val_acc: 0.9808\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0140 - acc: 0.9970 - val_loss: 0.0644 - val_acc: 0.9797\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0107 - acc: 0.9977 - val_loss: 0.0587 - val_acc: 0.9812\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0081 - acc: 0.9985 - val_loss: 0.0578 - val_acc: 0.9821\n",
      "CPU times: user 2min 20s, sys: 1min 11s, total: 3min 31s\n",
      "Wall time: 27.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f35de16ac88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 10, batch_size=200, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model against Test Data\n",
    "Test data and validation is used as the same. But, this should be ideally different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05781533238754491, 0.9821]\n",
      "Baseline Error: 1.79%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print (scores)\n",
    "print (\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"kerasDigitRecognizer.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Visual Test: Picking one of the inputs from Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the input image is 6\n"
     ]
    }
   ],
   "source": [
    "testInput = X_trainOrig[506]\n",
    "plt.imshow(testInput, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "# Preprocess - Flatten\n",
    "nrPixels = testInput.shape[0] * X_train.shape[1] # 28 * 28 = 784 pixels\n",
    "testInput_processed = testInput.reshape(1, num_pixels).astype('float32')\n",
    "# Preprocess - Normalization\n",
    "testInput_processed = testInput_processed/ 255\n",
    "# Prediction\n",
    "pred = model.predict(testInput_processed)\n",
    "print (\"Prediction for the input image is {}\".format(pred.argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
